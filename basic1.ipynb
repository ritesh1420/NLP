{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d63864",
   "metadata": {},
   "source": [
    "# 1.Conver in to lower case;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e6ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f4ec554",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Data/IMDB_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220df55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba5970e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2b7160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab023b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f23b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review']=data['review'].str.lower()\n",
    "#conver and store in your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d62cde6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. <br /><br />the...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c436a105",
   "metadata": {},
   "source": [
    "# 2.Remove unwanted symbol or thing from data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6b99d",
   "metadata": {},
   "source": [
    "# 2.1 Remove HTML tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "171f0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#  re stand for regular expression\n",
    "def remove_html_tag(text):\n",
    "    pattern=re.compile('<.*?>') #<.*?> html tag indicator \n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1140b640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This movie is slower '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"<br /><br />This movie is slower \"\n",
    "remove_html_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2d3aba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. the filming tec...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now apply it to hole dataset;\n",
    "data['review'].apply(remove_html_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f98c0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review']=data['review'].apply(remove_html_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e38267fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. the filming tec...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f0b58",
   "metadata": {},
   "source": [
    "# 2.2 Remove punchuation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d3510d",
   "metadata": {},
   "source": [
    "1.manual methode or normal method of removing punctuation which take long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74987478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string,time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "426518cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db4da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text=text.replace(char,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49e5be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='hey ../ how @are you*#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f541a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey  how are you\n",
      "time taken to remove punctuation: 60.35566329956055\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(remove_punc(text))\n",
    "time1=time.time()-start\n",
    "print(\"time taken to remove punctuation:\",time1*50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f77cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1='hey ../ how @are you*#'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a9e692",
   "metadata": {},
   "source": [
    "2.Faster method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "694822c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc1(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b061c349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey  how are you\n",
      "time taken to remove punctuation: 50.008296966552734\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(remove_punc1(text1))\n",
    "time2=time.time()-start\n",
    "print(\"time taken to remove punctuation:\",time2*50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f1b36b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second method is  1.2069129916567343  time faster then first method\n"
     ]
    }
   ],
   "source": [
    "print(\"second method is \",time1/time2, \" time faster then first method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26aab274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31955</th>\n",
       "      <td>this was the most visually stunning, moving, a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "31955  this was the most visually stunning, moving, a...  positive"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing from our actual data\n",
    "data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5233fbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production the filming tech...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically theres a family where a little boy j...\n",
       "4        petter matteis love in the time of money is a ...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot bad dialogue bad acting idiotic direc...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    im going to have to disagree with the previous...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'].apply(remove_punc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec7286bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production the filming tech...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically theres a family where a little boy j...  negative\n",
       "4  petter matteis love in the time of money is a ...  positive"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review']=data['review'].apply(remove_punc1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2c6a01",
   "metadata": {},
   "source": [
    "# 3.Spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1466ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' my friend is good person'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "incorrect_text=\" my friand is goode persion\"\n",
    "textBlb=TextBlob(incorrect_text)\n",
    "textBlb.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e65938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9294eb49",
   "metadata": {},
   "source": [
    "# 4.Remove Stop word\n",
    "stop work are those work which contribute in sentence formation like i,my,is,are,they etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45f854ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#Natural Language Toolkit(nltk)\n",
    "#corpus package contain the list of stopword in many languages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faca4f0",
   "metadata": {},
   "source": [
    "# Natural Language Toolkit(nltk)\n",
    "NLTK is a standard python library that provides a set of diverse algorithms for NLP. It is one of the most used libraries\n",
    "for NLP and Computational Linguistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ccf5949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63e0679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ritesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab842e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(text):\n",
    "    new_txt=[]\n",
    "    \n",
    "    for word in text.split(): #for break our word text by text\n",
    "        if(word in stopwords.words('english')):\n",
    "            new_txt.append('')\n",
    "        else:\n",
    "            new_txt.append(word)\n",
    "    x=new_txt[:] #copy new data which do not contain stopword;\n",
    "    new_txt.clear()# removing so that it can be used again ..\n",
    "    #if we not clear then data will be appended to old one\n",
    "        \n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6db693be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  going  markets'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"i am going to markets\"\n",
    "remove_stopword(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceddb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#appling in whole dataset;\n",
    "data['review']=data['review'].apply(remove_stopword)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733a0f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "print(emoji.demojize('this movies is ðŸ˜´'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc3db5",
   "metadata": {},
   "source": [
    "# 5.Tokenization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5dd226",
   "metadata": {},
   "source": [
    "5.1 using simple `split()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbfad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word tokennization\n",
    "sent1=\"I am going to delhi\"\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822bf0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2=\"I am going to delhi!\"\n",
    "sent2.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3873b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence tokenization\n",
    "sent3=\"I am going to delhi. You are comming with us?\"\n",
    "sent3.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c3dfa",
   "metadata": {},
   "source": [
    "..............................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1de84c",
   "metadata": {},
   "source": [
    "5.2 `Regular expression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ab4189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sent4='I am going to Delhi! and You will. come with #us?'\n",
    "result=re.findall(\"\\w+\",sent4)#for all punchuation\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6741995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text5=\"Natural language processing (NLP) is a machine learning technology that gives computers the ability to interpret, manipulate, and comprehend human language.\"\n",
    "result2=re.compile('[.,?]').split(text5)\n",
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9d574d",
   "metadata": {},
   "source": [
    "................................................................................................................"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fd3eab",
   "metadata": {},
   "source": [
    "5.3 `NLTK`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20650c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ac31f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', '@', 'going', 'to', '#', 'Delhi', '.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example1=\"I am @going to# Delhi.\"\n",
    "word_tokenize(example1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40c32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ffb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "example2=\"I have done Ph.D in A.I.\"\n",
    "word_tokenize(example2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3c63f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1='I have done #Ph.D in A.I.'\n",
    "ex2=\"We're here  mail on ritesh12@gmail.com\"\n",
    "ex3='A 5km ride cost is $10.50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5873ce57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'done', '#', 'Ph.D', 'in', 'A.I', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(ex1) #here works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(ex2) #fail in some case like gmail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef3d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(ex3) #fail in 5km"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a56d2",
   "metadata": {},
   "source": [
    "........................................................................"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb4eade",
   "metadata": {},
   "source": [
    "5.4 `Spacy` work more accurretly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a437068",
   "metadata": {},
   "source": [
    "# 6.Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d55fd1",
   "metadata": {},
   "source": [
    "Stemming is the process of removing the last few characters\n",
    "of a given word, to obtain a shorter form, even if that form doesnâ€™t have any meaning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bb9497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c449bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01294934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=\"walking  walked walks\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8a36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2=\"Stemming is the process of reducing a word to its stem that affixes to suffixes and prefixes or to the roots of words known as lemmas.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b0f19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stem is the process of reduc a word to it stem that affix to suffix and prefix or to the root of word known as lemmas.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(sample2) #fast\n",
    "#it do stemming but its not nessesary that it give right word. it do in it own style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752e987d",
   "metadata": {},
   "source": [
    "# 6.Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff1648",
   "metadata": {},
   "source": [
    "Lemmatization reduces the inflected words properly, ensuring the root word belongs to the language. \n",
    "In Lemmatization, the root word is called Lemma.\n",
    "A Lemma is a canonical form, dictionary form, or citation form of a set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf7604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma=WordNetLemmatizer()\n",
    "\n",
    "text='hii how are you? hope you are doing well.He played game '\n",
    "punctuation=\"?:!.,\"\n",
    "sentance_word=nltk.word_tokenize(text)\n",
    "for word in sentance_word:\n",
    "    if word in punctuation:\n",
    "        sentance_word.remove(word)\n",
    "sentance_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentance_word:\n",
    "    print(\"{0:20}{1:20}\".format(word,lemma.lemmatize(word,pos='v')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61734a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import nltk\n",
    ">>> nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "402353d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not good movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok not baad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i like this movies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               review\n",
       "0     not good movies\n",
       "1         ok not baad\n",
       "2  i like this movies"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "data1={\"review\":[\"not good movies\",\"ok not baad\",\"i like this movies\"]}\n",
    "df=pd.DataFrame(data1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e3a96f",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a4c377c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok not baad'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['review'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094df1df",
   "metadata": {},
   "source": [
    "# One Hot Encoding using `Bag of Word`\n",
    "**bag of word is a special case of `n-gram`\n",
    "**where ngram_range=(1,1) or we can say unigram\n",
    "**unigram means taking every word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ffe8e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect=CountVectorizer()\n",
    "bow=count_vect.fit_transform(df['review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5d9e2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'not': 4, 'good': 1, 'movies': 3, 'ok': 5, 'baad': 0, 'like': 2, 'this': 6}\n"
     ]
    }
   ],
   "source": [
    "#vocabulary\n",
    "print(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d7016da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1 0 0]]\n",
      "[[1 0 0 0 1 1 0]]\n",
      "[[0 0 1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())\n",
    "print(bow[1].toarray())\n",
    "print(bow[2].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865d9b0c",
   "metadata": {},
   "source": [
    "disadvantage\n",
    "\n",
    "1.`sparcity`\n",
    "2.`out of vocabulary`\n",
    "3.`ordering`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f50537",
   "metadata": {},
   "source": [
    "# One Hot Encoding using `n-gram`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "472747da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'not good': 3, 'good movies': 0, 'ok not': 4, 'not baad': 2, 'like this': 1, 'this movies': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect=CountVectorizer(ngram_range=(2,2))\n",
    "bow=count_vect.fit_transform(df['review'])\n",
    "print(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc1737b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1 0 0]]\n",
      "[[0 0 1 0 1 0]]\n",
      "[[0 1 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())\n",
    "print(bow[1].toarray())\n",
    "print(bow[2].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ac79629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'not': 6, 'good': 1, 'movies': 5, 'not good': 8, 'good movies': 2, 'ok': 9, 'baad': 0, 'ok not': 10, 'not baad': 7, 'like': 3, 'this': 11, 'like this': 4, 'this movies': 12}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect=CountVectorizer(ngram_range=(1,2))  #(1,2) means combination of 1 and twos words\n",
    "bow=count_vect.fit_transform(df['review'])\n",
    "print(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b634875a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'not good movies': 1, 'ok not baad': 2, 'like this movies': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect=CountVectorizer(ngram_range=(3,3))  #(3,3) means combination of 3 words\n",
    "bow=count_vect.fit_transform(df['review'])\n",
    "print(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8604655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]]\n",
      "[[0 0 1]]\n",
      "[[1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())\n",
    "print(bow[1].toarray())\n",
    "print(bow[2].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e113b6e",
   "metadata": {},
   "source": [
    "Disadvantage \n",
    "  **out of vocabulary\n",
    "  **Make algo slow\n",
    "  \n",
    "advantage\n",
    "   **simple\n",
    "   **able to captuare sementic of the sentance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aaba10",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f7b0e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.68091856, 0.        , 0.51785612, 0.51785612,\n",
       "        0.        , 0.        ],\n",
       "       [0.62276601, 0.        , 0.        , 0.        , 0.4736296 ,\n",
       "        0.62276601, 0.        ],\n",
       "       [0.        , 0.        , 0.62276601, 0.4736296 , 0.        ,\n",
       "        0.        , 0.62276601]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "TF_IDF=TfidfVectorizer()\n",
    "TF_IDF.fit_transform(df['review']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d8c9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.69314718 1.69314718 1.69314718 1.28768207 1.28768207 1.69314718\n",
      " 1.69314718]\n",
      "['baad' 'good' 'like' 'movies' 'not' 'ok' 'this']\n"
     ]
    }
   ],
   "source": [
    "print(TF_IDF.idf_)\n",
    "print(TF_IDF.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811ad2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
